S4-03
=======================================
Tartalom
---------------------------------------

1. [Többszálú programok ütemezése](#chapter01)
2. [A Java nyelv szinkronizációs eszközei](#chapter02)
3. [Jól szinkronizált programok, a happens-before reláció](#chapter03)
4. [Data race és race condition fogalma](#chapter04)
5. [Konkurrens használatra tervezett adatszerkezetek](#chapter05)
6. [Szinkronizáló osztályok](#chapter06)
7. [Szálak és feladatok](#chapter07)
8. [Félbeszakíthatóság](#chapter08)
9. [Haladási problémák (holtpont, kiéheztetés, livelock, priority inversion)](#chapter09)
10. [További források](#references)

**TODO:** Intrinsic locking leírása a synchronized résznél

**TODO:** Metódus- és osztálynevek highlight-olása code-szintaxissal

**TODO:** Tex-szintaxis levalidálása

1.Többszálú programok ütemezése <a name="chapter01"></a>
---------------------------------------
### Konkurens programok
* Programok, melyekben több végrehajtási stream hajtódik végre konkurensen. Ezeket az utasítás szekvenciákat hívjuk
 *szálaknak*.
* Minden ilyen szál ugyanúgy hajtódik végre, mint egy szekvenciális program
    + azzal a különbséggel, hogy a szálak képesek egymással kommunikálni
    + rosszul szervezett esetben akár *interferálni* is.
* Többszálú program esetén átfedések lehetségesek a folyamatok életciklusában, a különböző számítások nem kell, hogy
  ugyanabban az időben történjenek, bár előfordulhat, hogy párhuzamosan futnak le.
* **Nem determinisztikus** végrehajtás
* Problémát a megosztott, közösen használt adatokhoz való hozzáférés okozhatja

      $\Longrightarrow$ indokolt a megfelelő memória kezelés megoldása

### Párhuzamos programok
* Programok, melyeknél minden számítás a szó legszorosabb értelmében egyszerre történik
    + egy másik processzoron, vagy másik magon, esetleg egy másik gépen.
* Párhuzamos programokat lehetetlen egyszálú környezetben futtatni.
* Végrehajtásuk **determinisztikus** és eredményük megegyezik a soros végrehajtással.

### Ütemezés
#### Run-to-Completion
Egy folyamatot addig futtatunk,

* amíg kész nem lesz,
* vagy explicit vissza nem adja a vezérlést az ütemezőnek (`yield()`).

#### Pre-emption
Az aktuális szálat az ütemező megszakíthatja, és kontextusváltással egy másik szálat futtathat.

#### JVM implementációtól függő időosztás
Ekkor a szálak adott időszeleteket kapnak a végrehajtásra és kontextus váltásokat hajt végre köztük a JVM az idő
lejártakor, ha a szálak még mindig futtatható állapotban maradtak.

* Minden szálnak kioszt egy minimális időszelet (quantum), amit az kihasználhat
* ha ez túl kicsi, sok lesz a kontextusváltás, így nagy az ütemező overhead-je
* ha ez túl nagy, az egyes szálak "válaszideje" megnövekszik
* egy szál lemondhat az időszeletének további részéről `yield()` hívásával

2.A Java nyelv szinkronizációs eszközei <a name="chapter02"></a>
---------------------------------------
### Folyamatok (Process)
* Egy folyamat önálló futtatási környezettel rendelkezik.
* Több folyamat felépíthet egy alkalmazást
* Legtöbb JVM implementáció egy folyamatként fut
* Általában privát, teljes erőforrás halmazzal rendelkezik.
* A folyamatok izoláltam futnak egymástól, és nincs lehetőség közvetlenül egymás erőforrásaihoz hozzáférni.

### Szálak (Thread)
* Amolyan "pehelysúlyú folyamatok".
* Létrehozásuk kevesebb erőforrást igényel, mint a folyamatoké.
* A folyamatokon belül léteznek és minden folyamat rendelkezik legalább egy szállal.
* A szálak megosztják az erőforrásaikat, beleértve a memóriát is ami a kommunikáció alapját képezi.
* Működhetnek több CPU magon vagy egy magon időosztással

### java.lang.Thread
* Szinkronizációhoz alapul szolgáló eszközünk Java esetén maga a `java.lang.Thread` osztály.

Kétféle módszerrel definiálhatunk szálakat Java-ban:

1. **Thread osztályból származtatjuk az osztályunkat.** Ekkor felüldefiniáljuk a `Thread` osztály `run()` metódusát.
     Az osztályunknak lesz egy `start()` metódusa, amit meghívva elindíthatjuk a `run()` végrehajtását egy külön
     szálban.

      `new HelloThread()).start()`

2. **Megvalósítjuk a Runnable interfészt.** Adhatunk neki a konstruktorában egy Runnable interfészt megvalósító
     osztályt

      `new Thread(new HelloRunnable())).start()`


* Mindkét esetben a `run()` metódust kell felüldefiniálni
* Elindítani a `start()` metódussal lehet.


* Lehet prioritást rendelni hozzá,
* Futhat háttérszálként (daemon thread),
* Adhatunk neki nevet,
* JVM generál hozzá azonosítót (újrahasznosítható).

### Szálak életciklusa
Lehetséges ciklusok:

1. Létrejött (created)
2. Futtatható (runnable)
3. Futó (running)
4. Blokkolt (blocked)
5. Végetért (terminated)


* `start()`-al elindított szál futtatható (runnable) állapotba kerül, de ütemező még nem választotta ki.
* Ha az ütemező kiválasztja, futó (running) állapotba kerül, ekkor indul el a végrehajtása.
* Ha egy szál elkezdett futni, akkor addig fut, amíg az alábbiak valamelyike be nem következeik:
    + `Thread.sleep()` (blokkolt)
    + Lock-ra kezd várni, hogy egy `synchronized` metódust futtasson (blokkolt)
    + I/O-n blokkolódik (blokkolt)
    + Explicit visszaadja a vezérlést a `yield()`-el (futtathatóba kerül)
    + terminál, `run()` elfogy (véget ért)

#### Életciklusok változása
* `start()`: Létrejött $\Longrightarrow$ Futtatható
* ütemező: Futtatható $\Longrightarrow$ Futó
* `run()`: Futó $\Longrightarrow$ Véget ért
* `yield()`: Futó $\Longrightarrow$ Futtatható
* `sleep()`: Futó $\Longrightarrow$ Blokkolt
* `sleep()` vége: Blokkolt $\Longrightarrow$ Futtatható
* `interrupt()`: Blokkolt $\Longrightarrow$ Futtatható
* `wait()`: Futó $\Longrightarrow$ Blokkolt
* `notify()`: Blokkolt $\Longrightarrow$ Futtatható
* blokkoló IO: Futó $\Longrightarrow$ Blokkolt

### Szinkronizációs eszközök
#### Synchronized
**TODO:** JVM Intrinsic locking megvalósításáról írni

* Kizárólagos zárolást biztosít. Tartozik hozzá egy várakozási sor és kulcs.
* Kulcs azé az objektumé lesz, akié maga a metódus amin zároltunk.
* Mielőtt egy szál beléphetne egy szinkronizált metódusba, meg kell szereznie ezt a kulcsot. Ha rögtön nem elérhető, a
  várakozási sorban várakozik, kilépéskor pedig vissza kell adni ezt a kulcsot.
* Természetesen nem csak metódusokra implikálható, szinkronizációs blokkot is hozhatunk látre, melynek belsejében
  adhatjuk meg azokat az utasításokat melyekre kizárólagos hozzáférést szeretnénk biztosítani.
    + Ebben az esetben meg kell adni, hogy melyik objektum kulcsán akarunk szinkronizálni: `synchronized(obj) {...}`.
    + Létjogosultsága leginkább akkor van, ha nem egy objektumban vannak azok az utasítások amelyeken szinkronizálni
    akarunk vagy ha nem a this-en akarunk lock-olni.

#### Volatile
* Gyenge szinkronizációt biztosító eszköz (gyors, szálbiztos, lock-free hozzáférés).
* Explicit lock nélküli szinkronizációt biztosít, rákényszerítve a fordítót, hogy mindig olvassa ki a volatile változó
  értékét s így nem fordulhat elő az, hogy elavult (cache-elt) értéket kapjunk.
* Szálak között megosztott volatile változónak mindig az aktuális értékét látjuk minden szálban.
* A volatile olvasása/írása szinkronizációs akciót vált ki.
* Azért csak gyenge szinkronizációs eszköz, mert nincs kölcsönös kizárás a változó használatán, csak a láthatóságot
  biztosítja, atomiságot nem (a synchronized azt is).
* A fordító és runtime nem optimalizálhat rajta, azaz például nem rendezheti át az utasításokat rajtuk.
* Értékét nem szabad kizárólagosan egy szálra cache-elni.
* Nem menthetőek regiszterekbe.
* Használatuk leginkább az állapotjelzőkre, megszakítókra, kiegészítő feladatokra korlátozódik.
* Bármely volatile változó írása happens-before relációban kell legyen az utána következő olvasásaival.

#### Immutable (módosíthatatlan) objektumok
* A módosítathatlan objektumok szinkronizáció nélkül megoszthatóak a szálak között.
* Az ilyen objektumok mindig szálbiztosak, mert létrejöttük után nem változik az állapotuk.
* Invariánsaikat a konstruktor határozza meg.
* Egy objektum immutable, ha:
    + az állapota létrehozás után nem változtatható meg
    + minden mezője final (igazából technikailag nem feltétel)
    + biztonságosan jött létre, azaz nem szökött ki a this referencia a konstruálódása során
    + opcionálisan maga az osztály is lehet final
* Gyors allokációja és szinkronizációmentessége lévén gyors teljesítményt nyújt.
* Ha egy objektum nem immutable, a módosíthatatalan adattagokat akkor is érdemes megjelölni, ezáltal kevesebb
  lehetséges állapota lesz az objektumnak.
* Final mezőknél plusz garanciákat ad a memória modell: garantáltan inicializálva lesznek, mikor a konstruktor
  befejeződik.

3.Jól szinkronizált programok, a happens-before reláció <a name="chapter03"></a>
---------------------------------------
### Atomicitás
$A$ és $B$ művelet akkor atomi egymáshoz képest, ha az $A$ műveletet végrehajtó szál szempontjából a $B$
műveletet végrehajtó szál

* vagy teljes egészében végrehajtotta a műveletet
* vagy egyáltalán nem.

Egy művelet akkor atomi, ha ugyanazon az állapoton végrehajtott művelethez képest atomi, beleértve önmagát is.

### Happens-before reláció
#### "Laikus" magyarázat
* Kulcs memóriakonzisztencia hibák elkerülésére
* Ha egy esemény happens-before relációban áll a másikkal

      $\Longrightarrow$ az első esemény hatása látható a második
  számára

#### Definíció
Ha van $x$ és $y$ műveletünk $\Longrightarrow hb(x, y)$-al jelöljük hogy $x$ végrehajtása megelőzi $y$
végrehajtását ("x az y előtt történik", "x happens before y")

#### Mit garantál?
Garantálja, hogy ha két akció, $x$ és $y$ ilyen relációban áll, akkor $x$ eredménye látható $y$ számára.

#### Formálisabb definíció
A *program order* ($po$) és a *synchronizes-with* ($sw$ ) relációk uniójának tranzitív lezártja

$$hb = (po \cup sw)^+$$

Ebből tranzitív: ha $hb(a, b)$ és $hb(b, c)$ akkor $hb(a, c)$

#### $hb$-re vonatkozó szabályok:
* minden esemény egy szálon belül $hb$ relációban áll a többivel ha azok később következnek a program order szerint.
* Minden objektum konstruktorának vége relációban áll az objektum finalizer-ének első utasításával.
* Unlock monitor $hb$ relációban áll ugyanazon monitor lock-jával, amely utána következik
* `volatile` változó írása is $hb$ relációban áll az azt követő olvasásaival
* a szál `start()` metódusa $hb$ relációban áll minden más eseményével
* minden esemény egy szálon belül $hb$ relációban áll a többi szál `join()` általi visszatérésével

### Happens-before konzisztencia
* Happens-before konzisztens műveletek halmazában minden egyes olvasás olyan írást lát

      $\Longrightarrow$ ami olvasásnak megengedett, hogy happens-before sorrendben lássa


* Legyen
    + $A$: műveletek halmaza
    + $r$: olvasások $A$-ban
    + $W(r)$: írási műveletek, amiket $r$ lát

* Nem létezik olyan, hogy
    1. $hb(r, W(r)) \Longrightarrow$ olvasások happens-before relációban vannak az írásokkal amiket az olvasások
      látnak
    2. vagy pedig hogy létezik olyan $w$ írás $A$-ban, amiben
        + $w.v = r.v$
        + $hb(W(r), w)$
        + $hb(w, r)$

#### Miről biztosít a happens-before konzisztencia?
* Minden olvasás mely egy írás előtt ment végbe, nem láthatja annak az írásnak az eredményét
* Az olvasás akkor sem láthatja az írás eredményét ha épp egy másik írás van 	folyamatban

### Szekvenciális konzisztenica
* Minden változó olvasás $\Longrightarrow$ az előző írás eredményét látja egy megadott sorrend alapján, függetlenül
  attól, hogy melyik processzoron történtek a műveletek.
* Tehát minden akció atomi és eredménye minden szál számára azonnal látható.

Ha az egyes akciók teljes rendezésben vannak, amik konzisztensek a program order-el
  $\Longrightarrow$ akkor $v$ változó $r$ olvasása esetén, $v$ a $w$ által írt értéket látja, ha:

* $w$ az $r$ előtt áll
* nincs más $w'$ a $w$ és $r$ között.

### Jól szinkronizált program
* A program akkor és csak akkor jól szinkronizált, ha minden szekvenciálisan konzisztens végrehajtása data race-mentes.
* A jól szinkronizált programok minden végrehajtása szekvenciálisan konzisztensnek tűnik.

4.Data race és race condition fogalma <a name="chapter04"></a>
---------------------------------------
### Interferencia
* Két művelet különböző szálon fut, de ugyanazon az adaton dolgoznak

      $\Longrightarrow$ "összefésülődnek"

* A két művelet több lépésből állnak, ezek a lépések pedig összefolynak

### Check-then-act
* Egy állapotot megvizsgál (*check*), majd azalapján cselekszik egy szál (*act*)
* Am a két esemény közötti időben megváltozhat az eredetileg megvizsgált állapot.
* Másik megfogalmazás: Teendő elvégzéséhez (*act*) olyan megfigyelést (*check*) vesz alapul, ami valószínűleg elavult
  adatra épül
* Race condition alapja

### Data race
* Akkor következik be, mikor egy változót több szál olvas és legalább egy szál ír, viszont az írások és olvasások
  között nincs happens-before reláció.
* A jól szinkronizált program data race nélküli.
* Ha nincs data race, minden végrehajtás szekvenciálisan konzisztensnek tűnik

### Race condition:
Akkor következik be, mikor a számítás helyessége

1. a relatív időzítésen
2. vagy több szál futásidőben történő összesorolásán múlik.

Magyarul race condition esetén a helyes válasz a szerencsés időzítésen múlik ("szerencsén múlik").

* Megoldás: például szinkronizálás monitorral.

### Mitől szálbiztos (thread safe) egy program?
* *Read-modify-write* és *Check-then-act* utasítások atomikusan hajtódnak végre
* Nincs data race

5.Konkurrens használatra tervezett adatszerkezetek <a name="chapter05"></a>
---------------------------------------
### `Vector`, `Hashtable`
* Alapból szinkronizált (saját intrinsic lockjával).
* Szinkronizációs burkoló objektumot készítő, intrinsic lock-ot bevezető factory method-ok: `Collections.synchronized*`

#### Egy hibaforrás:
* Az iterálás során szintén zárolni kell az adatszerkezetet (atomi legyen, hogy közben ne változzon az elemszám), mert
  a szinkronizált kollekciók iterátorait nem kötelező lock-olni a bejárás közben.
* Így megfelelő zárolás hiányában egyszerű for-each bejárásnál vagy rejtett iterációnál (pl: `toString()`) nem lesz
  szálbiztos.

### `java.util.concurrent.*`
* A szinkronizált kollekciók (`Vector`, `Hashtable`) nem eléggé jó teljesítményűek, mivel a műveleteik az egész kollekciót
  zárolják.
* Ezzel szemben a konkurens kollekciók egyszerre írhatók és olvashatók több szálból.
* Nincs szükség lock-olásra az egész gyűjteményen (nem is ajánlott, mert elveszíti hatékonyságát), elég egy részén
  (lock striping).
* Atomi `putIfAbsent()`, `remove()` és `replace()` check-than-act típusú műveleteket biztosít.
* A `size()` illetve `isEmpty()` eredménye viszont csak approximális.

### `CopyOnWriteArrayList` és `CopyOnWriteArraySet`
* a `synchronizedList` párhuzamos megfelelője.
* Kiküszöböli  a gyűjtemény zárolásának vagy lemásolásának szükségességét bejárás közben.
* A `CopyOnWrite` gyűjtemények ereje abban rejlik
$\Longrightarrow$ hogy a gyűjtemény minden módosításakor másolatot készítenek  és tesznek közzé.
* Hatékony abban az esetben ha sok az olvasás és írás művelet rajtuk.

### `BlockingQueue`
* Blokkol, ha
    + nincs benne kivehető elem (kivételnél),
    + vagy tele van (berakásnál).
* Van felső határ nélküli változat is, itt a berakás soha nem blokkol.
* `poll()` és `offer()`: időhöz kötött várakozással blokkoló elem kivétel és berakás.

Fajtái:

  * `LinkedBlockingQueue`
  * `ArrayBlockingQueue`: igazából tömb típusú
  * `PriorityBlockingQueue`: nem FIFO típusú, prioritás számít
  * `SynchronousQueue`: igazából nincs eleme, de nem null az átadott érték
  * `BlockingDeque`: kétvégű változata

6.Szinkronizáló osztályok <a name="chapter06"></a>
---------------------------------------
Ezek közé bármi olyan objektum tartozik, ami a szálak vezérlését koordinálja saját állapota alapján.

### `Latch`
* Feltartja  a folyamatokat, amíg elér egy megadott termináló pontot.
* Feltart minden szálat míg el nem éri végállapotát, ezután mindet tovább engedi. A továbbiakban nem változik az
  állapota.
* Implementáció: például `CountdownLatch`, mely egy nem negatív értéktől számol vissza (`countDown()` csökkenti egyel)
  0-ig.

### `Semaphore`
* Klasszikus számláló szemafor (lehet bináris is), mely korlátozott számú erőforráshoz vagy korlátozott méretű
  adatszerkezethez való hozzáférést szabályozhat.
* Konstruktorában adható meg a szálak max. száma, melyek egyidőben bent tartózkodhatnak,

      $\Longrightarrow$ ez az érték fix egy szemaforra nézve.

### `Barrier`
* Egy bizonyos pont elérése után engedi tovább a szálakat (barrier pont).
* Alap implemetációja a `CyclicBarrier`, mely a kontruktorában megadott számú szálat vár be.
* Nincs végleges termináló állapota, újraindul.

### `Future`
* Interfész, egy aszinkron számítás eredményét reprezentálja.
* Eredményt `get()`-el kaphatjuk meg, mely addig blokkolódik, míg meg nem kapja az eredményt.
* Állapota lekérdezhető, félbeszakítható.
* FutureTask alap implementációja, egy aszinkron számítást végez.
* Konstruktorába `Callable` vagy `Runnable` objektumot kell adni
* Csak a számítás módját adjuk meg vele, a számítás elvégzését legtöbbször egy `Executor`-ra bízzuk.

7.Szálak és feladatok <a name="chapter07"></a>
---------------------------------------
#### Feladatok (task)
* A feladat az elvégzendő munka egy egysége.
* Ezeket konkurrensen hajtjuk végre szálakban.
* Ideális esetben egymástól
független az
    + állapotuk
    + eredményük
    + és mellékhatásaik is.

* Ha a feladatokat függetlenítjük a szálaktól (nincs explicit
összekapcsolás)

    $\Longrightarrow$ jobb skálázódási tulajdonságot kapunk.

A feladatok méretének meghatározása kritikus:

* Feladat/szál költséges lehet
* Túl kicsi feladatok: versengés, ütemezési overhead
* Túl nagy feladatok: kismértékű konkurrencia

4 folyamat / 4 feladat esetén a legnagyobb folyamat lesz a mérvadó sebesség terén.

#### `Executor`
* Feladatok beküldése végrehajtásra.
* `Executor` egy szálat több `Runnable` objektum végrehajtására tud felhasználni. Elosztja a beérkező feladatokat a
  szálak között.
* `ExecutorService` egy kiterjesztése az `Executor`-nak. A taszkok beküldésekor (`submit()`) nem csak `Runnable`-t,
  hanem `Callable`-t is elfogad, ez `Future`-t tud visszaadni.

8.Félbeszakíthatóság <a name="chapter08"></a>
---------------------------------------
### Szál félbeszakítása (`interrupt()`)
* Egyfajta üzenetküldés a szál megállításához, melyben közreműködik a kezdeményező, illetve az interruptot kapó szál
  is.
* Nem állíthat le egy szál egy másik még futásban lévő szálat, de megszakító kérést küldhet neki, amire a futásban lévő
  szál  megáll és átadja a vezérlést.
* Ezt egy kontextusváltás keretében teszi, mely magába foglalja a szál
    + stack-jének ürítését,
    + processzor regisztereinek ürítését,
    + cache ürítését
    + és a program counter elmentését. Ezután tölti be a másikét.
* Interrupt hívásakor beállítódik egy interrupt flag a szálban, ami lekérdezhető `interrupted()` és `isInterrupted()`
  segítségével.

### Feladat félbeszakítása (`cancel()`)
* Egy feladatot egy Future objektum reprezentál
* `cancel()` metódusában megadható, hogy megszakítható legyen-e

### Executor félbeszakítása (`shutdown()` vagy `shutDownNow()`)
* Minden szálnak van egyfajta implicit "tulajdonosa" (legtöbbször aki létrehozta) és a szál leállítását a tulajdonosa
  kell, hogy elvégezze,
* Ezért minden szálakat kezelő szolgáltatásnak kell legyen valamilyen shutdown mechanizmusa
* `shutdown()` megvárja míg az éppen futó szál befejezi feladatát és ezután állítja le, `shutdownNow()` meg is szakítja
  a jelenleg futó szálakat.

9.Haladási problémák (holtpont, kiéheztetés, livelock, priority inversion) <a name="chapter09"></a>
---------------------------------------
### Holtpont
* Folyamatok egy nem üres halmazát holtpontosnak nevezzük, ha a benne szereplő minden folyamat egy olyan feltétel
  bekövetkeztére vár (feltétlenül, időkorlát nélkül),
    + amely feltétel csak a halmazban lévő más folyamatok továbbhaladása esetén következhet be.
* Ha a halmaz minden folyamata arra vár, hogy sikerüljön lekötnie egy erőforrást,
    + amit egy, a halmazban lévő folyamat már lekötve tart,
    + akkor holtpont alakulhat ki.

#### Holtpont formális definíciója
1. Tekintsünk egy páros gráfot, amelynek csúcsai a folyamatokat, illetve az erőforrásokat reprezentálják.
2. Ha a folyamat zárolta azt az erőforrást

      $\rightarrow$ húzzunk be egy élt egy erőforrásból egy folyamatba

3. Ha a folyamat épp vár az erőforrás megszerzésére

      $\rightarrow$ húzzunk be egy élt egy folyamatból egy erőforrásba

4. Ha az így készített gráfban kör van

      $\Longrightarrow$ a körön lévő folyamatok holtpontba került folyamathalmazt adnak.

#### Étkező filozófusok példa
Ha minden filozófus felveszi a bal villáját

$\rightarrow$ majd elkezd várni arra, hogy felvehesse a jobb villát is

$\Longrightarrow$ holtpont alakult ki.

### Kiéheztetés
* Egy száltól huzamosabb ideig megtagadják azt az erőforrást, ami a továbbhaladásához szükséges.
* Sok esetben ez maga a végrehajtó egység, tehát egyszerűen nem kerül beütemezésre.
* Ez lehet például
    + a nem megfelelő szálprioritások megválasztásának eredménye
    + vagy ha egy szál úgy tart egy mások számára szükséges zárat, hogy közben végtelen ciklusba kerül.

### Livelock
* Szálak nem blokkolódnak, de valódi "haladás" nem történik.
* Olyan műveletet próbálnak végrehajtani, ami mindig sikertelen eredménnyel zárul.
* Például tranzakcionális üzenetsoroknál léphet fel ilyen, ha az üzenetek feldolgozása nem sikerül, és a sikertelen
  tranzakció esetén az üzenet visszakerül a sor elejére (poison message).
* Esetleg a szálak egymástól függően váltanak állaptotot, de pont úgy, hogy nem tudnak haladni.

### Priority inversion
* A fontosabb feladatok elvégzésése érdekében prioritást rendelhetünk a szálakhoz.
* Ha egy magasabb proritású folyamat futtathatóvá válik, akkor a rendszer késlelteti az alacsonyabb prioritású
  folyamatok futását.

#### Priority inversion formális definíciója
Legyen

* Két folyamat $H$ és $L$, amik magas és alacsony prioritásuak
* $M$ közepes prioritású folyamat
* Ezek egy
megosztott erőforrást akarnak megszerezni kizárólagos használatra, ami legyen $R$.

1. Ha $H$ próbálja megszerezni $R$-t miután $L$ megszerezte

      $\rightarrow$ H nem futtatható amíg $L$ el nem ereszti.

2. Mivel $H$ nem futtatható

      $\rightarrow$ ezért $M$ a legnagyobb prioritású folyamat

      $\rightarrow$ ami miatt $L$ késleltetődik és ezért $L$ nem tudja feloldani az erőforrást.

3. Ebben az esetben $\Longrightarrow$ a közepes prioritású $M$ folyamat megakadályozza hogy a magas prioritású
   $H$ folyamat futhasson.

10.További források <a name="references"></a>
---------------------------------------
* Előző kidolgozott záróvizsga tételek
* http://kto.web.elte.hu/hu/oktatas/eak2/
* https://docs.oracle.com/javase/tutorial/essential/concurrency/index.html
* https://docs.oracle.com/javase/specs/jls/se8/html/jls-17.html
* https://en.wikipedia.org/wiki/Java_memory_model
* https://en.wikipedia.org/wiki/Thread_safety
